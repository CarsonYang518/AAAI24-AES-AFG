{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18676,
     "status": "ok",
     "timestamp": 1690435601304,
     "user": {
      "displayName": "KaiXun Yang",
      "userId": "01445483365957018279"
     },
     "user_tz": -600
    },
    "id": "LVtG3HJf-TuQ",
    "outputId": "db51a011-c8bf-4a58-a70d-f85dbe20c780"
   },
   "outputs": [],
   "source": [
    "!pip install rsmtool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14859,
     "status": "ok",
     "timestamp": 1690435616158,
     "user": {
      "displayName": "KaiXun Yang",
      "userId": "01445483365957018279"
     },
     "user_tz": -600
    },
    "id": "juacyey7-bwn",
    "outputId": "0dd6f8ca-4cd1-4c39-b3d9-98f8a34c3769"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.utils.data as Data\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from tqdm import tqdm\n",
    "from rsmtool.utils.metrics import quadratic_weighted_kappa, difference_of_standardized_means, standardized_mean_difference\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from scipy.stats import pearsonr\n",
    "from rsmtool.fairness_utils import get_fairness_analyses\n",
    "from nltk.data import load\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.data import load\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "nltk.download('tagsets')\n",
    "tagdict = load('help/tagsets/upenn_tagset.pickle')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "pos_ids = {string: idx+1 for idx, string in enumerate(tagdict.keys())}\n",
    "pos_ids[\"#\"] = 46"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x719qbh3EeDx"
   },
   "outputs": [],
   "source": [
    "class CustomLoss(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(CustomLoss, self).__init__()\n",
    "\n",
    "  def forward(self, predictions, targets):\n",
    "    loss = torch.mean((predictions - targets) ** 2)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5qofclRs-eSn"
   },
   "outputs": [],
   "source": [
    "class WordAttNet(nn.Module):\n",
    "  def __init__(self, pos_size, hidden_size=100):\n",
    "    super(WordAttNet, self).__init__()\n",
    "    self.lookup = nn.Embedding(num_embeddings=pos_size, embedding_dim=50)\n",
    "    self.conv1 = nn.Conv1d(in_channels=50,out_channels=100,kernel_size=5)\n",
    "    self.dropout = nn.Dropout(p=0.5)\n",
    "    self.fc1 = nn.Linear( 100,100)\n",
    "    self.fc2 = nn.Linear( 100 , 1,bias =False)\n",
    "\n",
    "  def forward(self, input):\n",
    "    output = self.lookup(input)\n",
    "    output = self.dropout(output)\n",
    "    output = output.permute(1,2,0)\n",
    "    f_output = self.conv1(output.float())\n",
    "    f_output = f_output.permute(2,0,1)\n",
    "\n",
    "    weight = torch.tanh(self.fc1(f_output))\n",
    "    weight = self.fc2(weight)\n",
    "    weight = F.softmax(weight,0)\n",
    "    weight = weight * f_output\n",
    "    output = weight.sum(0).unsqueeze(0)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "62JwmDUxCoAa"
   },
   "outputs": [],
   "source": [
    "class SentAttNet(nn.Module):\n",
    "  def __init__(self, feature_size, sent_hidden_size=100, word_hidden_size=100):\n",
    "    super(SentAttNet, self).__init__()\n",
    "    self.LSTM = nn.LSTM(word_hidden_size, sent_hidden_size)\n",
    "    self.fc = nn.Linear(sent_hidden_size + feature_size, 1)\n",
    "    self.fc1 = nn.Linear(sent_hidden_size, sent_hidden_size)\n",
    "    self.fc2 = nn.Linear(sent_hidden_size , 1, bias =False)\n",
    "\n",
    "  def forward(self, input, feature):\n",
    "    f_output, _ = self.LSTM(input)\n",
    "    weight = torch.tanh(self.fc1(f_output))\n",
    "    weight = self.fc2(weight)\n",
    "    weight = F.softmax(weight,0)\n",
    "    weight = weight * f_output\n",
    "    output = weight.sum(0)\n",
    "    feature = feature.to(self.fc.weight.dtype)\n",
    "    final_output = torch.sigmoid(self.fc(torch.cat((output, feature), dim=1)))\n",
    "    return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "efhg-BiGCq4N"
   },
   "outputs": [],
   "source": [
    "class PAES(nn.Module):\n",
    "  def __init__(self, word_hidden_size, sent_hidden_size, batch_size, max_sent_length, max_word_length, feature_size, pos_size):\n",
    "    super(PAES, self).__init__()\n",
    "    self.batch_size = batch_size\n",
    "    self.word_hidden_size = word_hidden_size\n",
    "    self.sent_hidden_size = sent_hidden_size\n",
    "    self.max_sent_length = max_sent_length\n",
    "    self.max_word_length = max_word_length\n",
    "    self.word_att_net = WordAttNet(pos_size, word_hidden_size)\n",
    "    self.sent_att_net = SentAttNet(feature_size, sent_hidden_size, word_hidden_size)\n",
    "    self._init_hidden_state()\n",
    "\n",
    "  def _init_hidden_state(self, last_batch_size=None):\n",
    "    if last_batch_size:\n",
    "      batch_size = last_batch_size\n",
    "    else:\n",
    "      batch_size = self.batch_size\n",
    "      self.word_hidden_state = torch.zeros(2, batch_size, self.word_hidden_size)\n",
    "      self.sent_hidden_state = torch.zeros(2, batch_size, self.sent_hidden_size)\n",
    "      if torch.cuda.is_available():\n",
    "        self.word_hidden_state = self.word_hidden_state.cuda()\n",
    "        self.sent_hidden_state = self.sent_hidden_state.cuda()\n",
    "\n",
    "  def forward(self, input, feature):\n",
    "    output_list = torch.empty(0,).cuda()\n",
    "    input = input.permute(1, 0, 2)\n",
    "    for i in input:\n",
    "      output = self.word_att_net(i.permute(1, 0))\n",
    "      output_list = torch.cat((output_list, output))\n",
    "    final_output= self.sent_att_net(output_list, feature)\n",
    "    return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_rjgpzcOEQQo"
   },
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "  prompt_1 = pd.read_csv(path+'Prompt_1.csv')\n",
    "  prompt_2 = pd.read_csv(path+'Prompt_2.csv')\n",
    "  prompt_3 = pd.read_csv(path+'Prompt_3.csv')\n",
    "  prompt_4 = pd.read_csv(path+'Prompt_4.csv')\n",
    "  prompt_5 = pd.read_csv(path+'Prompt_5.csv')\n",
    "  prompt_6 = pd.read_csv(path+'Prompt_6.csv')\n",
    "  prompt_7 = pd.read_csv(path+'Prompt_7.csv')\n",
    "  prompt_8 = pd.read_csv(path+'Prompt_8.csv')\n",
    "  prompt_9 = pd.read_csv(path+'Prompt_9.csv')\n",
    "  prompt_10 = pd.read_csv(path+'Prompt_10.csv')\n",
    "  prompt_11 = pd.read_csv(path+'Prompt_11.csv')\n",
    "  prompt_12 = pd.read_csv(path+'Prompt_12.csv')\n",
    "  prompt_1_feat = pd.read_csv(path+'prompt_1_features_independent.csv')\n",
    "  prompt_2_feat = pd.read_csv(path+'prompt_2_features_independent.csv')\n",
    "  prompt_3_feat = pd.read_csv(path+'prompt_3_features_independent.csv')\n",
    "  prompt_4_feat = pd.read_csv(path+'prompt_4_features_independent.csv')\n",
    "  prompt_5_feat = pd.read_csv(path+'prompt_5_features_independent.csv')\n",
    "  prompt_6_feat = pd.read_csv(path+'prompt_6_features_independent.csv')\n",
    "  prompt_7_feat = pd.read_csv(path+'prompt_7_features_independent.csv')\n",
    "  prompt_8_feat = pd.read_csv(path+'prompt_8_features_independent.csv')\n",
    "  prompt_9_feat = pd.read_csv(path+'prompt_9_features_independent.csv')\n",
    "  prompt_10_feat = pd.read_csv(path+'prompt_10_features_independent.csv')\n",
    "  prompt_11_feat = pd.read_csv(path+'prompt_11_features_independent.csv')\n",
    "  prompt_12_feat = pd.read_csv(path+'prompt_12_features_independent.csv')\n",
    "\n",
    "  return [(prompt_1, prompt_1_feat), (prompt_2, prompt_2_feat),\n",
    "          (prompt_3, prompt_3_feat), (prompt_4, prompt_4_feat),\n",
    "          (prompt_5, prompt_5_feat), (prompt_6, prompt_6_feat),\n",
    "          (prompt_7, prompt_7_feat), (prompt_8, prompt_8_feat),\n",
    "          (prompt_9, prompt_9_feat), (prompt_10, prompt_10_feat),\n",
    "          (prompt_11, prompt_11_feat), (prompt_12, prompt_12_feat)]\n",
    "\n",
    "def split_data(data, fold):\n",
    "    kfold = KFold(n_splits=fold, shuffle=False)\n",
    "    results = []\n",
    "    for train_index, test_index in kfold.split(data):\n",
    "        results.append((train_index, test_index))\n",
    "    return results\n",
    "\n",
    "def accuracy_evaluation(y_pred, y_test):\n",
    "    qwk = quadratic_weighted_kappa(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    pearson_score = pearsonr(y_test, y_pred).statistic\n",
    "    return qwk, mae, pearson_score\n",
    "\n",
    "def fairness_evaluation(y_pred, y_test, demo_attribute):\n",
    "    df = pd.DataFrame({\"True_Score\":y_test, \"Prediction_Score\":y_pred, \"Demo\":demo_attribute})\n",
    "    results = get_fairness_analyses(df, group=\"Demo\", system_score_column=\"Prediction_Score\", human_score_column=\"True_Score\")[1].values()[3]\n",
    "    population_y_true_observed_sd = np.std(y_test)\n",
    "    population_y_true_observed_mn = np.mean(y_test)\n",
    "    population_y_pred_sd = np.std(y_pred)\n",
    "    population_y_pred_mn = np.mean(y_pred)\n",
    "    y_test_demo_0 = y_test[np.where(demo_attribute==0)]\n",
    "    y_test_demo_1 = y_test[np.where(demo_attribute==1)]\n",
    "    y_pred_demo_0 = y_pred[np.where(demo_attribute==0)]\n",
    "    y_pred_demo_1 = y_pred[np.where(demo_attribute==1)]\n",
    "    SMD_0 = difference_of_standardized_means(y_test_demo_0, y_pred_demo_0, population_y_true_observed_mn, population_y_pred_mn, population_y_true_observed_sd, population_y_pred_sd)\n",
    "    SMD_1 = difference_of_standardized_means(y_test_demo_1, y_pred_demo_1, population_y_true_observed_mn, population_y_pred_mn, population_y_true_observed_sd, population_y_pred_sd)\n",
    "    diff_mae = mean_absolute_error(y_test_demo_1, y_pred_demo_1) - mean_absolute_error(y_test_demo_0, y_pred_demo_0)\n",
    "    scores = pd.DataFrame({\"SMD_0\":[SMD_0], \"SMD_1\":[SMD_1], \"diff_mae\":[diff_mae]})\n",
    "    return results, scores\n",
    "\n",
    "def covert_label(y_pred):\n",
    "  range_min = 1\n",
    "  range_max = 6\n",
    "  y_orig = [(score*(range_max-range_min)+range_min) for score in y_pred]\n",
    "  return y_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cuNB7te6F_y8"
   },
   "outputs": [],
   "source": [
    "def get_features(texts, labels):\n",
    "  range_min = 1\n",
    "  range_max = 6\n",
    "  y = (labels-range_min)/(range_max-range_min)\n",
    "\n",
    "  maxSenNum = 0\n",
    "  maxSenLen = 0\n",
    "  documents = []\n",
    "  for text in texts:\n",
    "    sentences = sent_tokenize(text)\n",
    "    word_tokens = [[pos_ids[tag] for _, tag in pos_tag(word_tokenize(sentence), lang='eng')] for sentence in sentences]\n",
    "    documents.append(word_tokens)\n",
    "    if len(sentences) > maxSenNum:\n",
    "      maxSenNum = len(sentences)\n",
    "    if max([len(word_token) for word_token in word_tokens]) > maxSenLen:\n",
    "      maxSenLen = max([len(word_token) for word_token in word_tokens])\n",
    "\n",
    "  X = []\n",
    "  for document in documents:\n",
    "    X.append(pad_sequences(document, maxlen=maxSenLen))\n",
    "  max_shape = np.array(max(X, key=lambda x: x.shape)).shape\n",
    "  padded_X = np.array([np.pad(array, ((0, max_shape[0]-array.shape[0]), (0, max_shape[1]-array.shape[1])), mode='constant', constant_values=0) for array in X])\n",
    "  return padded_X, y, maxSenNum, maxSenLen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MhMaHytcYU5Q"
   },
   "outputs": [],
   "source": [
    "def get_features_for_test(texts, labels, maxSenNum, maxSenLen):\n",
    "  range_min = 1\n",
    "  range_max = 6\n",
    "  y = (labels-range_min)/(range_max-range_min)\n",
    "\n",
    "  documents = []\n",
    "  for text in texts:\n",
    "    sentences = sent_tokenize(text)\n",
    "    word_tokens = [[pos_ids[tag] for _, tag in pos_tag(word_tokenize(sentence), lang='eng')] for sentence in sentences]\n",
    "    documents.append(word_tokens)\n",
    "\n",
    "  X = []\n",
    "  for document in documents:\n",
    "    X.append(pad_sequences(document, maxlen=maxSenLen))\n",
    "  padded_X = np.array([np.pad(array, ((0, maxSenNum-array.shape[0]), (0, maxSenLen-array.shape[1])), mode='constant', constant_values=0) for array in X])\n",
    "  return padded_X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "azpSPOeqa4lR"
   },
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, train_dataloader, dev_dataloader, epochs):\n",
    "  best_qwk = float('-inf')\n",
    "  for i in range(0, epochs):\n",
    "    total_loss = 0\n",
    "    count = 0\n",
    "    model.train()\n",
    "    print(\"Epoch \" + str(i+1))\n",
    "    for iter, (feature_1, feature_2, label) in tqdm(enumerate(train_dataloader)):\n",
    "      model.zero_grad()\n",
    "      cuda_feature_1 = feature_1.cuda()\n",
    "      cuda_feature_2 = feature_2.cuda()\n",
    "      cuda_labels = label.cuda()\n",
    "      outputs = model(cuda_feature_1, cuda_feature_2)\n",
    "      loss = criterion(outputs, cuda_labels)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      total_loss += loss.item()\n",
    "      count += 1\n",
    "\n",
    "    qwk = evaluate(model, criterion, dev_dataloader)\n",
    "    if best_qwk < qwk:\n",
    "        best_qwk = qwk\n",
    "        torch.save(model.state_dict(), '')\n",
    "    print(\"Epoch {} complete, train loss: {}, dev qwk: {}\".format(i+1, total_loss/count, qwk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4cckrzDKa5Ju"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, criterion, dev_dataloader):\n",
    "  model.eval()\n",
    "  y_pred = []\n",
    "  y_true = []\n",
    "  with torch.no_grad():\n",
    "    for iter, (feature_1, feature_2, label) in enumerate(dev_dataloader):\n",
    "      cuda_feature_1 = feature_1.cuda()\n",
    "      cuda_feature_2 = feature_2.cuda()\n",
    "      cuda_labels = label.cuda()\n",
    "      outputs = model(cuda_feature_1, cuda_feature_2)\n",
    "\n",
    "      results = outputs.squeeze(-1)\n",
    "      results = results.detach().cpu().numpy()\n",
    "      for result in results:\n",
    "        y_pred.append(result)\n",
    "\n",
    "      labels = cuda_labels.squeeze(-1)\n",
    "      labels = labels.detach().cpu().numpy()\n",
    "      for label in labels:\n",
    "        y_true.append(label)\n",
    "  y_true = covert_label(y_true)\n",
    "  y_pred = covert_label(y_pred)\n",
    "  qwk = quadratic_weighted_kappa(y_true, y_pred)\n",
    "  return qwk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xGyYerUKa682"
   },
   "outputs": [],
   "source": [
    "def predict(model, dataloader):\n",
    "  model.eval()\n",
    "  y_pred = []\n",
    "  y_true = []\n",
    "  with torch.no_grad():\n",
    "    for iter, (feature_1, feature_2, label) in enumerate(dataloader):\n",
    "      cuda_feature_1 = feature_1.cuda()\n",
    "      cuda_feature_2 = feature_2.cuda()\n",
    "      cuda_labels = label.cuda()\n",
    "      outputs = model(cuda_feature_1, cuda_feature_2)\n",
    "\n",
    "      results = outputs.squeeze(-1)\n",
    "      results = results.detach().cpu().numpy()\n",
    "      for result in results:\n",
    "        y_pred.append(result)\n",
    "\n",
    "      labels = cuda_labels.squeeze(-1)\n",
    "      labels = labels.detach().cpu().numpy()\n",
    "      for label in labels:\n",
    "        y_true.append(label)\n",
    "  y_true = covert_label(y_true)\n",
    "  y_pred = covert_label(y_pred)\n",
    "  return np.array(y_pred), np.array(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zY01zpXoa8v9"
   },
   "outputs": [],
   "source": [
    "def run_experiment(seed):\n",
    "  df = pd.DataFrame(columns=[\"prompt\", \"fold\", \"quadratic_weighted_kappa\", \"mean_absolute_error\", \"pearson_correlation_coefficient\",\n",
    "                              \"OSA_gender\", \"OSA_gender_p_value\", \"OSD_gender\", \"OSD_gender_p_value\", \"CSD_gender\", \"CSD_gender_p_value\", \"SMD_1_gender\", \"SMD_0_gender\", \"MAED_gender\",\n",
    "                              \"OSA_Economically_disadvantaged\", \"OSA_Economically_disadvantaged_p_value\", \"OSD_Economically_disadvantaged\", \"OSD_Economically_disadvantaged_p_value\", \"CSD_Economically_disadvantaged\", \"CSD_Economically_disadvantaged_p_value\", \"SMD_1_Economically_disadvantaged\", \"SMD_0_Economically_disadvantaged\", \"MAED_Economically_disadvantaged\",\n",
    "                              \"OSA_Disability\", \"OSA_Disability_p_value\", \"OSD_Disability\", \"OSD_Disability_p_value\", \"CSD_Disability\", \"CSD_Disability_p_value\", \"SMD_1_Disability\", \"SMD_0_Disability\", \"MAED_Disability\",\n",
    "                              \"OSA_English_Language_Learner\", \"OSA_English_Language_Learner_p_value\", \"OSD_English_Language_Learner\", \"OSD_English_Language_Learner_p_value\", \"CSD_English_Language_Learner\", \"CSD_English_Language_Learner_p_value\", \"SMD_1_English_Language_Learner\", \"SMD_0_English_Language_Learner\", \"MAED_English_Language_Learner\",\n",
    "                              \"OSA_Race\", \"OSA_Race_p_value\", \"OSD_Race\", \"OSD_Race_p_value\", \"CSD_Race\", \"CSD_Race_p_value\", \"SMD_1_Race\", \"SMD_0_Race\", \"MAED_Race\"])\n",
    "  criterion = CustomLoss()\n",
    "  epochs = 50\n",
    "  prompts = load_data(\"\")\n",
    "  batch_size = 64\n",
    "    X_train_list = []\n",
    "    X_train_add_list = []\n",
    "    y_train_list = []\n",
    "    kfolds = []\n",
    "    for j in range(len(prompts)):\n",
    "      if j != i:\n",
    "        X_train_list.append(prompts[j][0]['Text'])\n",
    "        X_train_add_list.append(prompts[j][1])\n",
    "        y_train_list.append(prompts[j][0]['Overall'])\n",
    "      if j == i:\n",
    "        kfolds = split_data(prompts[j][0], 5)\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_add = scaler.fit_transform(pd.concat(X_train_add_list))\n",
    "    X, y, maxSenNum, maxSenLen = get_features(pd.concat(X_train_list).to_numpy(), pd.concat(y_train_list).to_numpy())\n",
    "    X_train, X_val, X_add_train, X_add_val, y_train, y_val = train_test_split(X, X_train_add, y, test_size=0.2, random_state=0)\n",
    "    print(maxSenNum, maxSenLen)\n",
    "    train_data = Data.TensorDataset(torch.tensor(X_train), torch.tensor(X_add_train), torch.tensor(y_train.reshape(-1, 1)))\n",
    "    val_data = Data.TensorDataset(torch.tensor(X_val), torch.tensor(X_add_val), torch.tensor(y_val.reshape(-1, 1)))\n",
    "    train_dataloader = Data.DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
    "    dev_dataloader = Data.DataLoader(dataset=val_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    model = PAES(100, 100, batch_size, maxSenNum, maxSenLen, 26, 47)\n",
    "    model.cuda()\n",
    "    optimizer = torch.optim.RMSprop(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001, alpha=0.9)\n",
    "    model.word_att_net.lookup.weight.requires_grad = True\n",
    "\n",
    "    train(model, optimizer, criterion, train_dataloader, dev_dataloader, epochs)\n",
    "\n",
    "    best_model = PAES(100, 100, batch_size, maxSenNum, maxSenLen, 26, 47)\n",
    "    best_model.cuda()\n",
    "    best_model.load_state_dict(torch.load(''))\n",
    "\n",
    "    for k in range(len(kfolds)):\n",
    "      print(\"Prompt \"+str(i+1)+\" Fold \"+str(k+1)+\":\")\n",
    "      X_test = prompts[i][0].iloc[kfolds[k][1]]['Text'].to_numpy()\n",
    "      test_info = prompts[i][0].iloc[kfolds[k][1]]\n",
    "      X_test_add = prompts[i][1].iloc[kfolds[k][1]]\n",
    "      y_test = prompts[i][0].iloc[kfolds[k][1]]['Overall'].to_numpy()\n",
    "\n",
    "      X_test, y_test = get_features_for_test(X_test, y_test, maxSenNum, maxSenLen)\n",
    "      X_test_add = scaler.fit_transform(X_test_add)\n",
    "      test_data = Data.TensorDataset(torch.tensor(X_test), torch.tensor(X_test_add), torch.tensor(y_test.reshape(-1, 1)))\n",
    "      test_dataloader = Data.DataLoader(dataset=test_data, batch_size=batch_size, shuffle=False)\n",
    "      y_pred, y_true = predict(best_model, test_dataloader)\n",
    "      qwk, mae, pearson_score = accuracy_evaluation(y_pred, y_true)\n",
    "      print(str(qwk), str(mae), str(pearson_score))\n",
    "      fairness_part1_Gender, fairness_part2_Gender = fairness_evaluation(y_pred, y_true, test_info['Gender'].to_numpy())\n",
    "      fairness_part1_Economically_disadvantaged, fairness_part2_Economically_disadvantaged = fairness_evaluation(y_pred, y_true, test_info['Economically_disadvantaged'].to_numpy())\n",
    "      fairness_part1_Disability, fairness_part2_Disability = fairness_evaluation(y_pred, y_true, test_info['Disability'].to_numpy())\n",
    "      fairness_part1_English_Language_Learner, fairness_part2_English_Language_Learner = fairness_evaluation(y_pred, y_true, test_info['English_Language_Learner'].to_numpy())\n",
    "      fairness_part1_Race, fairness_part2_Race = fairness_evaluation(y_pred, y_true, test_info['Race_Binary'].to_numpy())\n",
    "      new_row = {\"prompt\" : i+1, \"fold\": k+1, \"quadratic_weighted_kappa\": qwk, \"mean_absolute_error\": mae, \"pearson_correlation_coefficient\": pearson_score,\n",
    "                      \"OSA_gender\": fairness_part1_Gender['Overall score accuracy']['R2'],\n",
    "                      \"OSA_gender_p_value\": fairness_part1_Gender['Overall score accuracy']['sig'],\n",
    "                      \"OSD_gender\": fairness_part1_Gender['Overall score difference']['R2'],\n",
    "                      \"OSD_gender_p_value\": fairness_part1_Gender['Overall score difference']['sig'],\n",
    "                      \"CSD_gender\": fairness_part1_Gender['Conditional score difference']['R2'],\n",
    "                      \"CSD_gender_p_value\": fairness_part1_Gender['Conditional score difference']['sig'],\n",
    "                      \"SMD_1_gender\":fairness_part2_Gender['SMD_1'][0],\n",
    "                      \"SMD_0_gender\":fairness_part2_Gender['SMD_0'][0],\n",
    "                      \"MAED_gender\":fairness_part2_Gender['diff_mae'][0],\n",
    "                      \"OSA_Economically_disadvantaged\": fairness_part1_Economically_disadvantaged['Overall score accuracy']['R2'],\n",
    "                      \"OSA_Economically_disadvantaged_p_value\": fairness_part1_Economically_disadvantaged['Overall score accuracy']['sig'],\n",
    "                      \"OSD_Economically_disadvantaged\": fairness_part1_Economically_disadvantaged['Overall score difference']['R2'],\n",
    "                      \"OSD_Economically_disadvantaged_p_value\": fairness_part1_Economically_disadvantaged['Overall score difference']['sig'],\n",
    "                      \"CSD_Economically_disadvantaged\": fairness_part1_Economically_disadvantaged['Conditional score difference']['R2'],\n",
    "                      \"CSD_Economically_disadvantaged_p_value\": fairness_part1_Economically_disadvantaged['Conditional score difference']['sig'],\n",
    "                      \"SMD_1_Economically_disadvantaged\":fairness_part2_Economically_disadvantaged['SMD_1'][0],\n",
    "                      \"SMD_0_Economically_disadvantaged\":fairness_part2_Economically_disadvantaged['SMD_0'][0],\n",
    "                      \"MAED_Economically_disadvantaged\":fairness_part2_Economically_disadvantaged['diff_mae'][0],\n",
    "                      \"OSA_Disability\": fairness_part1_Disability['Overall score accuracy']['R2'],\n",
    "                      \"OSA_Disability_p_value\": fairness_part1_Disability['Overall score accuracy']['sig'],\n",
    "                      \"OSD_Disability\": fairness_part1_Disability['Overall score difference']['R2'],\n",
    "                      \"OSD_Disability_p_value\": fairness_part1_Disability['Overall score difference']['sig'],\n",
    "                      \"CSD_Disability\": fairness_part1_Disability['Conditional score difference']['R2'],\n",
    "                      \"CSD_Disability_p_value\": fairness_part1_Disability['Conditional score difference']['sig'],\n",
    "                      \"SMD_1_Disability\":fairness_part2_Disability['SMD_1'][0],\n",
    "                      \"SMD_0_Disability\":fairness_part2_Disability['SMD_0'][0],\n",
    "                      \"MAED_Disability\":fairness_part2_Disability['diff_mae'][0],\n",
    "                      \"OSA_English_Language_Learner\": fairness_part1_English_Language_Learner['Overall score accuracy']['R2'],\n",
    "                      \"OSA_English_Language_Learner_p_value\": fairness_part1_English_Language_Learner['Overall score accuracy']['sig'],\n",
    "                      \"OSD_English_Language_Learner\": fairness_part1_English_Language_Learner['Overall score difference']['R2'],\n",
    "                      \"OSD_English_Language_Learner_p_value\": fairness_part1_English_Language_Learner['Overall score difference']['sig'],\n",
    "                      \"CSD_English_Language_Learner\": fairness_part1_English_Language_Learner['Conditional score difference']['R2'],\n",
    "                      \"CSD_English_Language_Learner_p_value\": fairness_part1_English_Language_Learner['Conditional score difference']['sig'],\n",
    "                      \"SMD_1_English_Language_Learner\":fairness_part2_English_Language_Learner['SMD_1'][0],\n",
    "                      \"SMD_0_English_Language_Learner\":fairness_part2_English_Language_Learner['SMD_0'][0],\n",
    "                      \"MAED_English_Language_Learner\":fairness_part2_English_Language_Learner['diff_mae'][0],\n",
    "                      \"OSA_Race\": fairness_part1_Race['Overall score accuracy']['R2'],\n",
    "                      \"OSA_Race_p_value\": fairness_part1_Race['Overall score accuracy']['sig'],\n",
    "                      \"OSD_Race\": fairness_part1_Race['Overall score difference']['R2'],\n",
    "                      \"OSD_Race_p_value\": fairness_part1_Race['Overall score difference']['sig'],\n",
    "                      \"CSD_Race\": fairness_part1_Race['Conditional score difference']['R2'],\n",
    "                      \"CSD_Race_p_value\": fairness_part1_Race['Conditional score difference']['sig'],\n",
    "                      \"SMD_1_Race\":fairness_part2_Race['SMD_1'][0],\n",
    "                      \"SMD_0_Race\":fairness_part2_Race['SMD_0'][0],\n",
    "                      \"MAED_Race\":fairness_part2_Race['diff_mae'][0]}\n",
    "      df = df._append(new_row, ignore_index=True)\n",
    "    df.to_csv('', index=False)\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U2raLPAEi5rp"
   },
   "outputs": [],
   "source": [
    "run_experiment(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LWqxjyBC0FCK"
   },
   "outputs": [],
   "source": [
    "df.to_csv('', index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOpEC5Gz1fixIDIclQ52pj7",
   "gpuType": "V100",
   "machine_shape": "hm",
   "mount_file_id": "111OQIajcKklxGCnjKIgs3uPK4hhe6V_G",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
