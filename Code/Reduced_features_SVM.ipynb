{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d445b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from rsmtool.utils.metrics import quadratic_weighted_kappa, difference_of_standardized_means, standardized_mean_difference\n",
    "from scipy.stats import pearsonr\n",
    "from collections import Counter\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from rsmtool.fairness_utils import get_fairness_analyses\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471cc0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    prompt_1 = pd.read_csv(path+'Prompt_1.csv')\n",
    "    prompt_2 = pd.read_csv(path+'Prompt_2.csv')\n",
    "    prompt_3 = pd.read_csv(path+'Prompt_3.csv')\n",
    "    prompt_4 = pd.read_csv(path+'Prompt_4.csv')\n",
    "    prompt_5 = pd.read_csv(path+'Prompt_5.csv')\n",
    "    prompt_6 = pd.read_csv(path+'Prompt_6.csv')\n",
    "    prompt_7 = pd.read_csv(path+'Prompt_7.csv')\n",
    "    prompt_8 = pd.read_csv(path+'Prompt_8.csv')\n",
    "    prompt_9 = pd.read_csv(path+'Prompt_9.csv')\n",
    "    prompt_10 = pd.read_csv(path+'Prompt_10.csv')\n",
    "    prompt_11 = pd.read_csv(path+'Prompt_11.csv')\n",
    "    prompt_12 = pd.read_csv(path+'Prompt_12.csv')\n",
    "    prompt_1_features_independent = pd.read_csv(path+'Task-Independent Features for Automated Essay Grading/prompt_1_features_independent.csv')\n",
    "    prompt_2_features_independent = pd.read_csv(path+'Task-Independent Features for Automated Essay Grading/prompt_2_features_independent.csv')\n",
    "    prompt_3_features_independent = pd.read_csv(path+'Task-Independent Features for Automated Essay Grading/prompt_3_features_independent.csv')\n",
    "    prompt_4_features_independent = pd.read_csv(path+'Task-Independent Features for Automated Essay Grading/prompt_4_features_independent.csv')\n",
    "    prompt_5_features_independent = pd.read_csv(path+'Task-Independent Features for Automated Essay Grading/prompt_5_features_independent.csv')\n",
    "    prompt_6_features_independent = pd.read_csv(path+'Task-Independent Features for Automated Essay Grading/prompt_6_features_independent.csv')\n",
    "    prompt_7_features_independent = pd.read_csv(path+'Task-Independent Features for Automated Essay Grading/prompt_7_features_independent.csv')\n",
    "    prompt_8_features_independent = pd.read_csv(path+'Task-Independent Features for Automated Essay Grading/prompt_8_features_independent.csv')\n",
    "    prompt_9_features_independent = pd.read_csv(path+'Task-Independent Features for Automated Essay Grading/prompt_9_features_independent.csv')\n",
    "    prompt_10_features_independent = pd.read_csv(path+'Task-Independent Features for Automated Essay Grading/prompt_10_features_independent.csv')\n",
    "    prompt_11_features_independent = pd.read_csv(path+'Task-Independent Features for Automated Essay Grading/prompt_11_features_independent.csv')\n",
    "    prompt_12_features_independent = pd.read_csv(path+'Task-Independent Features for Automated Essay Grading/prompt_12_features_independent.csv')\n",
    "    return [(prompt_1, prompt_1_features_independent), (prompt_2, prompt_2_features_independent), (prompt_3, prompt_3_features_independent), (prompt_4, prompt_4_features_independent), (prompt_5, prompt_5_features_independent), (prompt_6, prompt_6_features_independent),\n",
    "          (prompt_7, prompt_7_features_independent), (prompt_8, prompt_8_features_independent), (prompt_9, prompt_9_features_independent), (prompt_10, prompt_10_features_independent), (prompt_11, prompt_11_features_independent), (prompt_12, prompt_12_features_independent)]\n",
    "\n",
    "def accuracy_evaluation(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    qwk = quadratic_weighted_kappa(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    pearson_score = pearsonr(y_test, y_pred).statistic\n",
    "    return qwk, mae, pearson_score\n",
    "\n",
    "def fairness_evaluation(model, X_test, y_test, demo_attribute):\n",
    "    y_pred = model.predict(X_test)\n",
    "    df = pd.DataFrame({\"True_Score\":y_test, \"Prediction_Score\":y_pred, \"Demo\":demo_attribute})\n",
    "    results = get_fairness_analyses(df, group=\"Demo\", system_score_column=\"Prediction_Score\", human_score_column=\"True_Score\")[1].values()[3]\n",
    "    population_y_true_observed_sd = np.std(y_test)\n",
    "    population_y_true_observed_mn = np.mean(y_test)\n",
    "    population_y_pred_sd = np.std(y_pred)\n",
    "    population_y_pred_mn = np.mean(y_pred)\n",
    "    y_test_demo_0 = y_test[np.where(demo_attribute==0)]\n",
    "    y_test_demo_1 = y_test[np.where(demo_attribute==1)]\n",
    "    y_pred_demo_0 = y_pred[np.where(demo_attribute==0)]\n",
    "    y_pred_demo_1 = y_pred[np.where(demo_attribute==1)]\n",
    "    SMD_0 = difference_of_standardized_means(y_test_demo_0, y_pred_demo_0, population_y_true_observed_mn, population_y_pred_mn, population_y_true_observed_sd, population_y_pred_sd)\n",
    "    SMD_1 = difference_of_standardized_means(y_test_demo_1, y_pred_demo_1, population_y_true_observed_mn, population_y_pred_mn, population_y_true_observed_sd, population_y_pred_sd)\n",
    "    diff_mae = mean_absolute_error(y_test_demo_1, y_pred_demo_1) - mean_absolute_error(y_test_demo_0, y_pred_demo_0)\n",
    "    scores = pd.DataFrame({\"SMD_0\":[SMD_0], \"SMD_1\":[SMD_1], \"diff_mae\":[diff_mae]})\n",
    "    return results, scores\n",
    "\n",
    "def split_data(data, fold):\n",
    "    kfold = KFold(n_splits=fold, shuffle=False)\n",
    "    results = []\n",
    "    for train_index, test_index in kfold.split(data):\n",
    "        results.append((train_index, test_index))\n",
    "    return results\n",
    "\n",
    "def prompt_wise_cross_validation(prompts_list):\n",
    "    df = pd.DataFrame(columns=[\"prompt\", \"fold\", \"quadratic_weighted_kappa\", \"mean_absolute_error\", \"pearson_correlation_coefficient\",\n",
    "                              \"OSA_gender\", \"OSA_gender_p_value\", \"OSD_gender\", \"OSD_gender_p_value\", \"CSD_gender\", \"CSD_gender_p_value\", \"SMD_1_gender\", \"SMD_0_gender\", \"MAED_gender\",\n",
    "                              \"OSA_Economically_disadvantaged\", \"OSA_Economically_disadvantaged_p_value\", \"OSD_Economically_disadvantaged\", \"OSD_Economically_disadvantaged_p_value\", \"CSD_Economically_disadvantaged\", \"CSD_Economically_disadvantaged_p_value\", \"SMD_1_Economically_disadvantaged\", \"SMD_0_Economically_disadvantaged\", \"MAED_Economically_disadvantaged\",\n",
    "                              \"OSA_Disability\", \"OSA_Disability_p_value\", \"OSD_Disability\", \"OSD_Disability_p_value\", \"CSD_Disability\", \"CSD_Disability_p_value\", \"SMD_1_Disability\", \"SMD_0_Disability\", \"MAED_Disability\",\n",
    "                              \"OSA_English_Language_Learner\", \"OSA_English_Language_Learner_p_value\", \"OSD_English_Language_Learner\", \"OSD_English_Language_Learner_p_value\", \"CSD_English_Language_Learner\", \"CSD_English_Language_Learner_p_value\", \"SMD_1_English_Language_Learner\", \"SMD_0_English_Language_Learner\", \"MAED_English_Language_Learner\",\n",
    "                              \"OSA_Race\", \"OSA_Race_p_value\", \"OSD_Race\", \"OSD_Race_p_value\", \"CSD_Race\", \"CSD_Race_p_value\", \"SMD_1_Race\", \"SMD_0_Race\", \"MAED_Race\"])\n",
    "    for i in tqdm(range(len(prompts_list))):\n",
    "        X_train_list = []\n",
    "        y_train_list = []\n",
    "        kfolds = []\n",
    "        for j in range(len(prompts_list)):\n",
    "            if j != i:\n",
    "                X_train_list.append(prompts_list[j][1])\n",
    "                y_train_list.append(prompts_list[j][0]['Overall'])\n",
    "            if j == i:\n",
    "                kfolds = split_data(prompts_list[j][1], 5)\n",
    "        ssc = StandardScaler()\n",
    "        X_train = ssc.fit_transform(pd.concat(X_train_list))\n",
    "        y_train = pd.concat(y_train_list).to_numpy()\n",
    "        model = SVR()\n",
    "        model.fit(X_train, y_train)\n",
    "        for k in range(len(kfolds)):\n",
    "            print(\"Prompt \"+str(i)+\" Fold \"+str(k)+\":\")\n",
    "            X_test = prompts_list[i][1].iloc[kfolds[k][1]]\n",
    "            y_test = prompts_list[i][0].iloc[kfolds[k][1]]['Overall'].to_numpy()\n",
    "            y_info = prompts_list[i][0].iloc[kfolds[k][1]]\n",
    "            X_test = ssc.transform(X_test)\n",
    "            qwk, mae, pearson_score = accuracy_evaluation(model, X_test, y_test)\n",
    "            fairness_part1_Gender, fairness_part2_Gender = fairness_evaluation(model, X_test, y_test, y_info['Gender'].to_numpy())\n",
    "            fairness_part1_Economically_disadvantaged, fairness_part2_Economically_disadvantaged = fairness_evaluation(model, X_test, y_test, y_info['Economically_disadvantaged'].to_numpy())\n",
    "            fairness_part1_Disability, fairness_part2_Disability = fairness_evaluation(model, X_test, y_test, y_info['Disability'].to_numpy())\n",
    "            fairness_part1_English_Language_Learner, fairness_part2_English_Language_Learner = fairness_evaluation(model, X_test, y_test, y_info['English_Language_Learner'].to_numpy())\n",
    "            fairness_part1_Race, fairness_part2_Race = fairness_evaluation(model, X_test, y_test, y_info['Race_Binary'].to_numpy())\n",
    "            new_row = {\"prompt\" : i+1, \"fold\": k+1, \"quadratic_weighted_kappa\": qwk, \"mean_absolute_error\": mae, \"pearson_correlation_coefficient\": pearson_score,\n",
    "                      \"OSA_gender\": fairness_part1_Gender['Overall score accuracy']['R2'],\n",
    "                      \"OSA_gender_p_value\": fairness_part1_Gender['Overall score accuracy']['sig'],\n",
    "                      \"OSD_gender\": fairness_part1_Gender['Overall score difference']['R2'],\n",
    "                      \"OSD_gender_p_value\": fairness_part1_Gender['Overall score difference']['sig'],\n",
    "                      \"CSD_gender\": fairness_part1_Gender['Conditional score difference']['R2'],\n",
    "                      \"CSD_gender_p_value\": fairness_part1_Gender['Conditional score difference']['sig'],\n",
    "                      \"SMD_1_gender\":fairness_part2_Gender['SMD_1'][0],\n",
    "                      \"SMD_0_gender\":fairness_part2_Gender['SMD_0'][0],\n",
    "                      \"MAED_gender\":fairness_part2_Gender['diff_mae'][0],\n",
    "                      \"OSA_Economically_disadvantaged\": fairness_part1_Economically_disadvantaged['Overall score accuracy']['R2'],\n",
    "                      \"OSA_Economically_disadvantaged_p_value\": fairness_part1_Economically_disadvantaged['Overall score accuracy']['sig'],\n",
    "                      \"OSD_Economically_disadvantaged\": fairness_part1_Economically_disadvantaged['Overall score difference']['R2'],\n",
    "                      \"OSD_Economically_disadvantaged_p_value\": fairness_part1_Economically_disadvantaged['Overall score difference']['sig'],\n",
    "                      \"CSD_Economically_disadvantaged\": fairness_part1_Economically_disadvantaged['Conditional score difference']['R2'],\n",
    "                      \"CSD_Economically_disadvantaged_p_value\": fairness_part1_Economically_disadvantaged['Conditional score difference']['sig'],\n",
    "                      \"SMD_1_Economically_disadvantaged\":fairness_part2_Economically_disadvantaged['SMD_1'][0],\n",
    "                      \"SMD_0_Economically_disadvantaged\":fairness_part2_Economically_disadvantaged['SMD_0'][0],\n",
    "                      \"MAED_Economically_disadvantaged\":fairness_part2_Economically_disadvantaged['diff_mae'][0],\n",
    "                      \"OSA_Disability\": fairness_part1_Disability['Overall score accuracy']['R2'],\n",
    "                      \"OSA_Disability_p_value\": fairness_part1_Disability['Overall score accuracy']['sig'],\n",
    "                      \"OSD_Disability\": fairness_part1_Disability['Overall score difference']['R2'],\n",
    "                      \"OSD_Disability_p_value\": fairness_part1_Disability['Overall score difference']['sig'],\n",
    "                      \"CSD_Disability\": fairness_part1_Disability['Conditional score difference']['R2'],\n",
    "                      \"CSD_Disability_p_value\": fairness_part1_Disability['Conditional score difference']['sig'],\n",
    "                      \"SMD_1_Disability\":fairness_part2_Disability['SMD_1'][0],\n",
    "                      \"SMD_0_Disability\":fairness_part2_Disability['SMD_0'][0],\n",
    "                      \"MAED_Disability\":fairness_part2_Disability['diff_mae'][0],\n",
    "                      \"OSA_English_Language_Learner\": fairness_part1_English_Language_Learner['Overall score accuracy']['R2'],\n",
    "                      \"OSA_English_Language_Learner_p_value\": fairness_part1_English_Language_Learner['Overall score accuracy']['sig'],\n",
    "                      \"OSD_English_Language_Learner\": fairness_part1_English_Language_Learner['Overall score difference']['R2'],\n",
    "                      \"OSD_English_Language_Learner_p_value\": fairness_part1_English_Language_Learner['Overall score difference']['sig'],\n",
    "                      \"CSD_English_Language_Learner\": fairness_part1_English_Language_Learner['Conditional score difference']['R2'],\n",
    "                      \"CSD_English_Language_Learner_p_value\": fairness_part1_English_Language_Learner['Conditional score difference']['sig'],\n",
    "                      \"SMD_1_English_Language_Learner\":fairness_part2_English_Language_Learner['SMD_1'][0],\n",
    "                      \"SMD_0_English_Language_Learner\":fairness_part2_English_Language_Learner['SMD_0'][0],\n",
    "                      \"MAED_English_Language_Learner\":fairness_part2_English_Language_Learner['diff_mae'][0],\n",
    "                      \"OSA_Race\": fairness_part1_Race['Overall score accuracy']['R2'],\n",
    "                      \"OSA_Race_p_value\": fairness_part1_Race['Overall score accuracy']['sig'],\n",
    "                      \"OSD_Race\": fairness_part1_Race['Overall score difference']['R2'],\n",
    "                      \"OSD_Race_p_value\": fairness_part1_Race['Overall score difference']['sig'],\n",
    "                      \"CSD_Race\": fairness_part1_Race['Conditional score difference']['R2'],\n",
    "                      \"CSD_Race_p_value\": fairness_part1_Race['Conditional score difference']['sig'],\n",
    "                      \"SMD_1_Race\":fairness_part2_Race['SMD_1'][0],\n",
    "                      \"SMD_0_Race\":fairness_part2_Race['SMD_0'][0],\n",
    "                      \"MAED_Race\":fairness_part2_Race['diff_mae'][0]}\n",
    "            df = df.append(new_row, ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bc29be",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = load_data(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade39d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = prompt_wise_cross_validation(prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5794718",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.to_csv('', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5a3c70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
