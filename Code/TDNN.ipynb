{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13985,
     "status": "ok",
     "timestamp": 1690906272878,
     "user": {
      "displayName": "KaiXun Yang",
      "userId": "01445483365957018279"
     },
     "user_tz": -600
    },
    "id": "EwrkKtIRCmFL",
    "outputId": "6e04f1e7-8261-44d6-99ab-a28693aaec0f"
   },
   "outputs": [],
   "source": [
    "!pip install rsmtool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12542,
     "status": "ok",
     "timestamp": 1690906285414,
     "user": {
      "displayName": "KaiXun Yang",
      "userId": "01445483365957018279"
     },
     "user_tz": -600
    },
    "id": "Wsbg_sbPDBii",
    "outputId": "3f9e6b58-7260-4d58-ce18-5b53d00e7eb4"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rsmtool.utils.metrics import quadratic_weighted_kappa, difference_of_standardized_means, standardized_mean_difference\n",
    "from collections import Counter\n",
    "from keras.layers import Input, Embedding, Bidirectional, LSTM, TimeDistributed, Dense, Convolution1D, GlobalMaxPooling1D, concatenate, Dropout, BatchNormalization, Activation\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from rsmtool.utils.metrics import quadratic_weighted_kappa, difference_of_standardized_means, standardized_mean_difference\n",
    "from rsmtool.fairness_utils import get_fairness_analyses\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import EarlyStopping\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7572,
     "status": "ok",
     "timestamp": 1690906292966,
     "user": {
      "displayName": "KaiXun Yang",
      "userId": "01445483365957018279"
     },
     "user_tz": -600
    },
    "id": "ALuhGiNWxlo7"
   },
   "outputs": [],
   "source": [
    "fp1=open(\"\",\"r\")\n",
    "glove_emb={}\n",
    "for line in fp1:\n",
    "\ttemp=line.split(\" \")\n",
    "\tglove_emb[temp[0]]=np.asarray([float(i) for i in temp[1:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1690906292967,
     "user": {
      "displayName": "KaiXun Yang",
      "userId": "01445483365957018279"
     },
     "user_tz": -600
    },
    "id": "QeU1Qdq7DEbj"
   },
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "  prompt_1 = pd.read_csv(path+'Prompt_1.csv')\n",
    "  prompt_2 = pd.read_csv(path+'Prompt_2.csv')\n",
    "  prompt_3 = pd.read_csv(path+'Prompt_3.csv')\n",
    "  prompt_4 = pd.read_csv(path+'Prompt_4.csv')\n",
    "  prompt_5 = pd.read_csv(path+'Prompt_5.csv')\n",
    "  prompt_6 = pd.read_csv(path+'Prompt_6.csv')\n",
    "  prompt_7 = pd.read_csv(path+'Prompt_7.csv')\n",
    "  prompt_8 = pd.read_csv(path+'Prompt_8.csv')\n",
    "  prompt_9 = pd.read_csv(path+'Prompt_9.csv')\n",
    "  prompt_10 = pd.read_csv(path+'Prompt_10.csv')\n",
    "  prompt_11 = pd.read_csv(path+'Prompt_11.csv')\n",
    "  prompt_12 = pd.read_csv(path+'Prompt_12.csv')\n",
    "  prompt_1_score = pd.read_csv('/content/drive/MyDrive/AES/Rank_SVM/pseudo_1.csv')\n",
    "  prompt_2_score = pd.read_csv('/content/drive/MyDrive/AES/Rank_SVM/pseudo_2.csv')\n",
    "  prompt_3_score = pd.read_csv('/content/drive/MyDrive/AES/Rank_SVM/pseudo_3.csv')\n",
    "  prompt_4_score = pd.read_csv('/content/drive/MyDrive/AES/Rank_SVM/pseudo_4.csv')\n",
    "  prompt_5_score = pd.read_csv('/content/drive/MyDrive/AES/Rank_SVM/pseudo_5.csv')\n",
    "  prompt_6_score = pd.read_csv('/content/drive/MyDrive/AES/Rank_SVM/pseudo_6.csv')\n",
    "  prompt_7_score = pd.read_csv('/content/drive/MyDrive/AES/Rank_SVM/pseudo_7.csv')\n",
    "  prompt_8_score = pd.read_csv('/content/drive/MyDrive/AES/Rank_SVM/pseudo_8.csv')\n",
    "  prompt_9_score = pd.read_csv('/content/drive/MyDrive/AES/Rank_SVM/pseudo_9.csv')\n",
    "  prompt_10_score = pd.read_csv('/content/drive/MyDrive/AES/Rank_SVM/pseudo_10.csv')\n",
    "  prompt_11_score = pd.read_csv('/content/drive/MyDrive/AES/Rank_SVM/pseudo_11.csv')\n",
    "  prompt_12_score = pd.read_csv('/content/drive/MyDrive/AES/Rank_SVM/pseudo_12.csv')\n",
    "\n",
    "  return [(prompt_1, prompt_1_score), (prompt_2, prompt_2_score),\n",
    "          (prompt_3, prompt_3_score), (prompt_4, prompt_4_score),\n",
    "          (prompt_5, prompt_5_score), (prompt_6, prompt_6_score),\n",
    "          (prompt_7, prompt_7_score), (prompt_8, prompt_8_score),\n",
    "          (prompt_9, prompt_9_score), (prompt_10, prompt_10_score),\n",
    "          (prompt_11, prompt_11_score), (prompt_12, prompt_12_score)]\n",
    "\n",
    "def covert_label(scores):\n",
    "  range_min = 1\n",
    "  range_max = 6\n",
    "  scaled_scores = (scores-range_min)/(range_max-range_min)\n",
    "  return scaled_scores\n",
    "\n",
    "def get_training_samples(texts, scaled_scores):\n",
    "  scaled_scores_temp = scaled_scores*9 + 1\n",
    "  negative_index = np.where(scaled_scores_temp<=4)[0]\n",
    "  positive_index = np.where(scaled_scores_temp>=8)[0]\n",
    "  combined_array = np.concatenate((negative_index, positive_index))\n",
    "  return texts[combined_array], scaled_scores[combined_array]\n",
    "\n",
    "def get_features(texts):\n",
    "  tokenizer=Tokenizer(num_words=4000, oov_token = \"<unk>\")\n",
    "  tokenizer.fit_on_texts(texts)\n",
    "  word_index=tokenizer.word_index\n",
    "  essayset = []\n",
    "  for text in texts:\n",
    "    sentences = nltk.tokenize.sent_tokenize(text)\n",
    "    essay = []\n",
    "    essay = tokenizer.texts_to_sequences(sentences)\n",
    "    essay1 = pad_sequences(essay, 40, padding='post')\n",
    "    essayset.append(essay1)\n",
    "  maxlen = max([len(x) for x in essayset])\n",
    "  essayset = pad_sequences(essayset, maxlen, padding='post')\n",
    "  return essayset, word_index\n",
    "\n",
    "def split_data(data, fold):\n",
    "    kfold = KFold(n_splits=fold, shuffle=False)\n",
    "    results = []\n",
    "    for train_index, test_index in kfold.split(data):\n",
    "        results.append((train_index, test_index))\n",
    "    return results\n",
    "\n",
    "def accuracy_evaluation(y_pred, y_test):\n",
    "    qwk = quadratic_weighted_kappa(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    pearson_score = pearsonr(y_test, y_pred).statistic\n",
    "    return qwk, mae, pearson_score\n",
    "\n",
    "def fairness_evaluation(y_pred, y_test, demo_attribute):\n",
    "    df = pd.DataFrame({\"True_Score\":y_test, \"Prediction_Score\":y_pred, \"Demo\":demo_attribute})\n",
    "    results = get_fairness_analyses(df, group=\"Demo\", system_score_column=\"Prediction_Score\", human_score_column=\"True_Score\")[1].values()[3]\n",
    "    population_y_true_observed_sd = np.std(y_test)\n",
    "    population_y_true_observed_mn = np.mean(y_test)\n",
    "    population_y_pred_sd = np.std(y_pred)\n",
    "    population_y_pred_mn = np.mean(y_pred)\n",
    "    y_test_demo_0 = y_test[np.where(demo_attribute==0)]\n",
    "    y_test_demo_1 = y_test[np.where(demo_attribute==1)]\n",
    "    y_pred_demo_0 = y_pred[np.where(demo_attribute==0)]\n",
    "    y_pred_demo_1 = y_pred[np.where(demo_attribute==1)]\n",
    "    SMD_0 = difference_of_standardized_means(y_test_demo_0, y_pred_demo_0, population_y_true_observed_mn, population_y_pred_mn, population_y_true_observed_sd, population_y_pred_sd)\n",
    "    SMD_1 = difference_of_standardized_means(y_test_demo_1, y_pred_demo_1, population_y_true_observed_mn, population_y_pred_mn, population_y_true_observed_sd, population_y_pred_sd)\n",
    "    diff_mae = mean_absolute_error(y_test_demo_1, y_pred_demo_1) - mean_absolute_error(y_test_demo_0, y_pred_demo_0)\n",
    "    scores = pd.DataFrame({\"SMD_0\":[SMD_0], \"SMD_1\":[SMD_1], \"diff_mae\":[diff_mae]})\n",
    "    return results, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1690906292967,
     "user": {
      "displayName": "KaiXun Yang",
      "userId": "01445483365957018279"
     },
     "user_tz": -600
    },
    "id": "6YVuJUE0mafq"
   },
   "outputs": [],
   "source": [
    "def model_essay(maxSenLen, vocab_size, embedding_dim, hidden_dim, dense_dim, word_index):\n",
    "  embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "  for word,i in word_index.items():\n",
    "    if i >= vocab_size:\n",
    "      continue\n",
    "    if word in glove_emb:\n",
    "      embedding_matrix[i]=glove_emb[word]\n",
    "  input_words = Input(shape=(maxSenLen,), dtype='int32')\n",
    "  embedding_layer = Embedding(input_dim=vocab_size, output_dim=embedding_dim, weights=[embedding_matrix], trainable=True, mask_zero=True)(input_words)\n",
    "  bi_lstm_layer = Bidirectional(LSTM(units=hidden_dim, return_sequences=False), merge_mode='concat')(embedding_layer)\n",
    "  sentence_model = Model(inputs=input_words, outputs=bi_lstm_layer)\n",
    "  input_essay = Input(shape=(None, maxSenLen), dtype='int32')\n",
    "  essay_layer = TimeDistributed(sentence_model)(input_essay)\n",
    "  essay_bilstm_layer = Bidirectional(LSTM(units=hidden_dim, return_sequences=False), merge_mode='concat')(essay_layer)\n",
    "  bn_merge_layer2 = BatchNormalization()(essay_bilstm_layer)\n",
    "  merge_dense_layer2 = Dense(dense_dim, activation='relu')(bn_merge_layer2)\n",
    "  score_layer = Dense(1, activation='sigmoid', name='pred_score')(merge_dense_layer2)\n",
    "  essay_model = Model(inputs=input_essay, outputs=score_layer)\n",
    "  optimizer = optimizers.Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=1e-08, clipnorm=0, clipvalue=10)\n",
    "  essay_model.compile(optimizer=optimizer, loss=\"mean_squared_error\", metrics=['mean_squared_error'])\n",
    "  return essay_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 508,
     "status": "ok",
     "timestamp": 1690907077777,
     "user": {
      "displayName": "KaiXun Yang",
      "userId": "01445483365957018279"
     },
     "user_tz": -600
    },
    "id": "Z9ru9Q454xXU"
   },
   "outputs": [],
   "source": [
    "def run_experiment(seed):\n",
    "  df = pd.DataFrame(columns=[\"prompt\", \"fold\", \"quadratic_weighted_kappa\", \"mean_absolute_error\", \"pearson_correlation_coefficient\",\n",
    "                            \"OSA_gender\", \"OSA_gender_p_value\", \"OSD_gender\", \"OSD_gender_p_value\", \"CSD_gender\", \"CSD_gender_p_value\", \"SMD_1_gender\", \"SMD_0_gender\", \"MAED_gender\",\n",
    "                            \"OSA_Economically_disadvantaged\", \"OSA_Economically_disadvantaged_p_value\", \"OSD_Economically_disadvantaged\", \"OSD_Economically_disadvantaged_p_value\", \"CSD_Economically_disadvantaged\", \"CSD_Economically_disadvantaged_p_value\", \"SMD_1_Economically_disadvantaged\", \"SMD_0_Economically_disadvantaged\", \"MAED_Economically_disadvantaged\",\n",
    "                            \"OSA_Disability\", \"OSA_Disability_p_value\", \"OSD_Disability\", \"OSD_Disability_p_value\", \"CSD_Disability\", \"CSD_Disability_p_value\", \"SMD_1_Disability\", \"SMD_0_Disability\", \"MAED_Disability\",\n",
    "                            \"OSA_English_Language_Learner\", \"OSA_English_Language_Learner_p_value\", \"OSD_English_Language_Learner\", \"OSD_English_Language_Learner_p_value\", \"CSD_English_Language_Learner\", \"CSD_English_Language_Learner_p_value\", \"SMD_1_English_Language_Learner\", \"SMD_0_English_Language_Learner\", \"MAED_English_Language_Learner\",\n",
    "                            \"OSA_Race\", \"OSA_Race_p_value\", \"OSD_Race\", \"OSD_Race_p_value\", \"CSD_Race\", \"CSD_Race_p_value\", \"SMD_1_Race\", \"SMD_0_Race\", \"MAED_Race\"])\n",
    "  prompts = load_data(\"\")\n",
    "  i = 0\n",
    "  for prompt in prompts:\n",
    "    print(\"Prompt\"+str(i+1))\n",
    "    X, word_index = get_features(prompt[0][\"Text\"].to_numpy())\n",
    "    y = covert_label(prompt[1].to_numpy().reshape(-1))\n",
    "    y_real = covert_label(prompt[0][\"Overall\"].to_numpy())\n",
    "\n",
    "    X_train, y_train = get_training_samples(X, y)\n",
    "    kfolds = split_data(prompt[0], 5)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=seed)\n",
    "\n",
    "    earlystopping = EarlyStopping(monitor=\"val_loss\", patience=5)\n",
    "    model = model_essay(40, 4000, 50, 50, 50, word_index)\n",
    "    hist = model.fit([X_train], y_train, batch_size=16, epochs=50, validation_data=([X_val], y_val), callbacks=[earlystopping])\n",
    "    k = 0\n",
    "    for kfold in kfolds:\n",
    "      X_test = X[kfold[1]]\n",
    "      y_test = y_real[kfold[1]]*5+1\n",
    "      test_info = prompt[0].iloc[kfold[1]]\n",
    "      y_pred = model.predict(X_test).reshape(-1)\n",
    "      y_pred = y_pred*5+1\n",
    "      qwk, mae, pearson_score = accuracy_evaluation(y_pred, y_test)\n",
    "      print(str(qwk), str(mae), str(pearson_score))\n",
    "      fairness_part1_Gender, fairness_part2_Gender = fairness_evaluation(y_pred, y_test, test_info['Gender'].to_numpy())\n",
    "      fairness_part1_Economically_disadvantaged, fairness_part2_Economically_disadvantaged = fairness_evaluation(y_pred, y_test, test_info['Economically_disadvantaged'].to_numpy())\n",
    "      fairness_part1_Disability, fairness_part2_Disability = fairness_evaluation(y_pred, y_test, test_info['Disability'].to_numpy())\n",
    "      fairness_part1_English_Language_Learner, fairness_part2_English_Language_Learner = fairness_evaluation(y_pred, y_test, test_info['English_Language_Learner'].to_numpy())\n",
    "      fairness_part1_Race, fairness_part2_Race = fairness_evaluation(y_pred, y_test, test_info['Race_Binary'].to_numpy())\n",
    "      new_row = {\"prompt\" : i+1, \"fold\": k+1, \"quadratic_weighted_kappa\": qwk, \"mean_absolute_error\": mae, \"pearson_correlation_coefficient\": pearson_score,\n",
    "                      \"OSA_gender\": fairness_part1_Gender['Overall score accuracy']['R2'],\n",
    "                      \"OSA_gender_p_value\": fairness_part1_Gender['Overall score accuracy']['sig'],\n",
    "                      \"OSD_gender\": fairness_part1_Gender['Overall score difference']['R2'],\n",
    "                      \"OSD_gender_p_value\": fairness_part1_Gender['Overall score difference']['sig'],\n",
    "                      \"CSD_gender\": fairness_part1_Gender['Conditional score difference']['R2'],\n",
    "                      \"CSD_gender_p_value\": fairness_part1_Gender['Conditional score difference']['sig'],\n",
    "                      \"SMD_1_gender\":fairness_part2_Gender['SMD_1'][0],\n",
    "                      \"SMD_0_gender\":fairness_part2_Gender['SMD_0'][0],\n",
    "                      \"MAED_gender\":fairness_part2_Gender['diff_mae'][0],\n",
    "                      \"OSA_Economically_disadvantaged\": fairness_part1_Economically_disadvantaged['Overall score accuracy']['R2'],\n",
    "                      \"OSA_Economically_disadvantaged_p_value\": fairness_part1_Economically_disadvantaged['Overall score accuracy']['sig'],\n",
    "                      \"OSD_Economically_disadvantaged\": fairness_part1_Economically_disadvantaged['Overall score difference']['R2'],\n",
    "                      \"OSD_Economically_disadvantaged_p_value\": fairness_part1_Economically_disadvantaged['Overall score difference']['sig'],\n",
    "                      \"CSD_Economically_disadvantaged\": fairness_part1_Economically_disadvantaged['Conditional score difference']['R2'],\n",
    "                      \"CSD_Economically_disadvantaged_p_value\": fairness_part1_Economically_disadvantaged['Conditional score difference']['sig'],\n",
    "                      \"SMD_1_Economically_disadvantaged\":fairness_part2_Economically_disadvantaged['SMD_1'][0],\n",
    "                      \"SMD_0_Economically_disadvantaged\":fairness_part2_Economically_disadvantaged['SMD_0'][0],\n",
    "                      \"MAED_Economically_disadvantaged\":fairness_part2_Economically_disadvantaged['diff_mae'][0],\n",
    "                      \"OSA_Disability\": fairness_part1_Disability['Overall score accuracy']['R2'],\n",
    "                      \"OSA_Disability_p_value\": fairness_part1_Disability['Overall score accuracy']['sig'],\n",
    "                      \"OSD_Disability\": fairness_part1_Disability['Overall score difference']['R2'],\n",
    "                      \"OSD_Disability_p_value\": fairness_part1_Disability['Overall score difference']['sig'],\n",
    "                      \"CSD_Disability\": fairness_part1_Disability['Conditional score difference']['R2'],\n",
    "                      \"CSD_Disability_p_value\": fairness_part1_Disability['Conditional score difference']['sig'],\n",
    "                      \"SMD_1_Disability\":fairness_part2_Disability['SMD_1'][0],\n",
    "                      \"SMD_0_Disability\":fairness_part2_Disability['SMD_0'][0],\n",
    "                      \"MAED_Disability\":fairness_part2_Disability['diff_mae'][0],\n",
    "                      \"OSA_English_Language_Learner\": fairness_part1_English_Language_Learner['Overall score accuracy']['R2'],\n",
    "                      \"OSA_English_Language_Learner_p_value\": fairness_part1_English_Language_Learner['Overall score accuracy']['sig'],\n",
    "                      \"OSD_English_Language_Learner\": fairness_part1_English_Language_Learner['Overall score difference']['R2'],\n",
    "                      \"OSD_English_Language_Learner_p_value\": fairness_part1_English_Language_Learner['Overall score difference']['sig'],\n",
    "                      \"CSD_English_Language_Learner\": fairness_part1_English_Language_Learner['Conditional score difference']['R2'],\n",
    "                      \"CSD_English_Language_Learner_p_value\": fairness_part1_English_Language_Learner['Conditional score difference']['sig'],\n",
    "                      \"SMD_1_English_Language_Learner\":fairness_part2_English_Language_Learner['SMD_1'][0],\n",
    "                      \"SMD_0_English_Language_Learner\":fairness_part2_English_Language_Learner['SMD_0'][0],\n",
    "                      \"MAED_English_Language_Learner\":fairness_part2_English_Language_Learner['diff_mae'][0],\n",
    "                      \"OSA_Race\": fairness_part1_Race['Overall score accuracy']['R2'],\n",
    "                      \"OSA_Race_p_value\": fairness_part1_Race['Overall score accuracy']['sig'],\n",
    "                      \"OSD_Race\": fairness_part1_Race['Overall score difference']['R2'],\n",
    "                      \"OSD_Race_p_value\": fairness_part1_Race['Overall score difference']['sig'],\n",
    "                      \"CSD_Race\": fairness_part1_Race['Conditional score difference']['R2'],\n",
    "                      \"CSD_Race_p_value\": fairness_part1_Race['Conditional score difference']['sig'],\n",
    "                      \"SMD_1_Race\":fairness_part2_Race['SMD_1'][0],\n",
    "                      \"SMD_0_Race\":fairness_part2_Race['SMD_0'][0],\n",
    "                      \"MAED_Race\":fairness_part2_Race['diff_mae'][0]}\n",
    "      df = df.append(new_row, ignore_index=True)\n",
    "      k += 1\n",
    "    df.to_csv('', index=False)\n",
    "    i += 1\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1858752,
     "status": "ok",
     "timestamp": 1690908946826,
     "user": {
      "displayName": "KaiXun Yang",
      "userId": "01445483365957018279"
     },
     "user_tz": -600
    },
    "id": "Z_tC4tEa3Vyt",
    "outputId": "edf6b57a-f6cc-4eaf-9951-3fda84a8a68c"
   },
   "outputs": [],
   "source": [
    "run_experiment(0)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOsdRAFPTEDU0546eBdBzIe",
   "gpuType": "T4",
   "machine_shape": "hm",
   "mount_file_id": "15QhBpofKsEeZlSFzq3OrzjPwiABGlX8W",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
